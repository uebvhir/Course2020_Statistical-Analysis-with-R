---
title: "Hypotheses tests with continuous variables"
author: "Miriam Mota and Santiago Perez-Hoyos"
date: "Statistics and Bioinformatics Unit. Vall d'Hebron Institut de Recerca"
output:
  beamer_presentation:
    theme: "Madrid"
    colortheme: "dolphin"
    fonttheme: "structurebold"
    slide_level: 2
footer: "Statistics with R"
editor_options: 
  chunk_output_type: console
---

```{r, echo = FALSE, results = 'hide', message = F}
require(knitr)
# include this code chunk as-is to set options
opts_chunk$set(fig.width = 7, fig.height = 3, warning = F, message = FALSE)

```

# Outline

- Introduction

- Type of Tests

- Normality Tests

- One Group Comparison

- Two Groups Comparison in Independent Samples

- Two Groups Comparison in Dependent Samples

- K Groups Comparison in Independent Samples

- Multiple Comparisons and Multiple Testing




# Introduction 

- Once the concept of hypothesis testing is established, 
- Researchers face the problem of _which test should be applied at every possible situation_.
- For this, ideally, they should... 
  - understand the problem and the questions addressed,
  - know available tests for each problem,
  - know (how to check) applicability assumptions of each test,
  - know how robust each test is to assumptions violation.
- Easier to say than to do. 
  - Sometimes cheatsheets may be helpful, but be warned against a blind use, that is understand and be critic with the steps. 

# Which test is appropriate for which problem

```{r, echo=FALSE, out.width="80%", out.length="60%", fig.cap=""}
knitr::include_graphics("images/testsXCadaSituacio.png")
```


# Example situation (1): Introduction

- Many experimental questions may be answered through hypothesis testing.
- Imagine, for example, a study designed to compare two distinct hypertension control programs.
- 60 individuals with HTA were randomly assigned to either one or the other group (30 per group) 
- Blood pressure was measured each month during a year 
  - For simplicity we may keep only data at months 1 and 12

```{r loadlibs, echo=FALSE, include=FALSE}
require(pacman)
p_load(dplyr, readxl, magrittr, ggplot2)
```

---

# Example situation (2): Data collected

```{r readExampleData , echo=TRUE}
hta <- read_excel("datasets/hta.xls")
htaSimple <- hta %>% select(grupo, sexo, tas1, tad1, tas12, tad12)
head(as.data.frame(htaSimple))
```

<!-- - Exercise: modify the code to create two new variables "difftas=tas12-tas1" and "difftad=tad12-tad1". -->

---

# Example situation (3): Reasonable questions

- The goal of the study is to compare the treatment effect
so a reasonable question is:
  - *Is the average decrease in "tad" the same in both groups A and B?*

- Or, if we are testing a new treatment "B", hat is intended to be batter than "A"
  - *Is the average decrease in "tad" greater in group B?*
  
- *Although they are not planned in this study* other relevant questions may lead to questions that need a test to be answered, such as:
  - *Is the average `tad` above 150?*
  - *Has the average `tad` (in group A) decreased in 12 months?*
  - *Is the average `tad` different in men and women at basal time?*
  
---

# Types of tests (1): Confirmatory vs Independence

Distinct classifications can be found in textbooks

- Confirmatory
  - Is average HTA above 150?
  - Is the the tas1 variable normally distributed
- Independence
  - Is sex related to HTA (or is mean(HTA) the same in men or women)
  - Is average HTA decrease the same for both groups?

- *This classification is useful but artificial, not to say that the term "independence" is slightly abused*

---

# Types of tests (2): Parametric vs Non-parametric

- Parametric tests 
  - assume some underlying distribution for the data
  - pose the test in terms of the distribution's parameters
    - E.g. the t-test assumes normality and relies on the normal and t-distribution's parameters
  
- Non-parametric tests
  - Do not assume an underlying distribution, but they are not assumption-free!
  - Check: [Distribution free is not assumption free](https://www.isixsigma.com/hypothesis-testing/nonparametric-distribution-free-not-assumption-free/)
  
- Permutation tests
  - If sample size is not tiny *permutation tests* are a good alternative.

---
# Hands on: Always start looking at the data

\tiny

```{r , eval=FALSE}
library(ggplot2)
library(patchwork)

p1 <- ggplot(hta, aes(y = tas1)) +
  geom_boxplot() 

p2 <- ggplot(hta, aes(x = tas1)) +
  geom_histogram() 

p3 <- ggplot(hta, aes(sample = tas1)) +
  stat_qq() +
  stat_qq_line() 

(p1 | p2) / p3

```

\normalsize
# Hands on: Always start looking at the data

\tiny

```{r , eval=FALSE}
p_load(ggplot2, patchwork)

p1 <- ggplot(hta, aes(y = tas1)) +
  geom_boxplot(fill = "skyblue") +
  labs(title = "Box-plot", y = "tas1") 

p2 <- ggplot(hta, aes(x = tas1)) +
  geom_histogram(bins = 30, fill = "salmon", color = "black") +
  labs(title = "Histograma", x = "tas1")

p3 <- ggplot(hta, aes(sample = tas1)) +
  stat_qq() +
  stat_qq_line(color = "blue") +
  labs(title = "QQ plot", x = "Teórico", y = "Muestra") 

(p1 | p2) / p3

```

\normalsize
---

# Data visualization

```{r , echo=FALSE}
p_load(ggplot2, patchwork)
p1 <- ggplot(hta, aes(y = tas1)) +
  geom_boxplot() 

p2 <- ggplot(hta, aes(x = tas1)) +
  geom_histogram() 

p3 <- ggplot(hta, aes(sample = tas1)) +
  stat_qq() +
  stat_qq_line() 

(p1 | p2) / (p3 | plot_spacer())
```

---

# Normality and tests

- The choice of test seems to pivot around the question of ¿is my data normally distributed?

- Leaving apart a tence to repeat what we have been taught, why is this so?

  - If the data is normally distributed there exist some *optimal tests* for some one or two sample problems.
  - Data show often a bell-shaped form that can be assimilated to have a gaussian distribution (it is *normal* to observe this).
  - Iven if data is not bell-shaped, if sample size is big enough th sample mean tends to be bell -shaped as sample size increase.
  
- In summary, normality is not only "practical" but common.

- As a consequence checking normality has become one of the first steps of any data analysis. 
  - It doesn't hurt, but it is clearly over-rated.

---

# Normality Test

- Normality tests can be used to decide if the data can be considered to follow a normal distribution.
- This is more a theoretical than practical issue because ...
  - If the sample size is too small, the test is not powerful enough.
  - If the sample size is too big, the test will almost always reject the normality htypothesis
  
- Normality can be tested 
  - Graphically:
    - Check if it is a symmetric distribution
    - Probability graphs (QQ-plots)
  - Using Hypothesis test (Normality)
    - Kolmogorov tests
    - Shapiro-Wilks test

# Normality test: Shapiro-Wilks

- In normality test, the null hypothesis is normality
- That is, rejecting the null suggests departure of normality.
  - $H_0$: The data follow a normal distribution
  - $H_1$: The data do not follow a normal distribution

```{r normtest , mysize=TRUE, size='\\small'}
shapiro.test(hta$tad1)  # Shapiro Wilk test

```


# One sample tests

- One sample tests refer to a single characteristic of the population such as:
  - *Is it true that the average tad in HTA population is above 150*?
  
- It is often said that they are less interesting because they are rarely used in most practical situations where the main goal is comparison

- *However*, noticing that a paired tests is equivalent to a one sample tests for the difference makes us realize their relevance.


# One sample parametric vs non-parametric tests

- If we assume normality an appropriate test for a hypothesis about the mean is the *t-test*

  - $H_0: \mu=\mu_0,\qquad H_1: \mu \neq \mu_0,\, (\mu > \mu_0,\, \mu< \mu_0)$.
  
- If we don't assume normality we can rely on
  - Wilcoxon rank test, if data re symmetrical
  - Sign test in other cases

# Hands on one sample tests (1): t-test

- Is `tad` in HTA patients above 90?
- Notice that even if we are interested in "above 90" the null is "equality"

  - $H_0: \mu=90,\qquad H_1: \mu > 90$.


```{r onettest , mysize=TRUE, size='\\small'}
t.test(hta$tad1,mu=90, alternative="greater") # One sample T.test
```

# Hands on one sample tests (2): Wilcoxon test

- In wilcoxon test the null hypothesis is about the median.

```{r onewilcoxtest , mysize=TRUE, size='\\small'}
wilcox.test(hta$tad1,mu=90, alternative="greater")  # One sample wilcoxon
```


# Homogeneity variance Test


```{r vartest , mysize=TRUE, size='\\small'}
library(car)
hta %>% 
  group_by(sexo) %>% 
  summarise(var = sd(tas1)) 


leveneTest(hta$tad1~factor(hta$sexo),center="median")

```
  - p value is over 0.05
  - We can assume homogeneity of variances
  
  
  
# T test when variances are equal



```{r eqttest , mysize=TRUE, size='\\small'}
t.test(hta$tas1~factor(hta$sexo), var.equal = TRUE )

```
- Type I Error is over than 0.05
- We cannot reject mean equality



  
# T test when variances are unequal



```{r neqttest , mysize=TRUE, size='\\small'}
t.test(hta$tas1~factor(hta$sexo),var.equal=FALSE )

```
- Same conclusions as before
- Test is also known as Welch test



  
# U Mann-Whitney or Sum Rank non parametric test



```{r umtest , mysize=TRUE, size='\\small'}
wilcox.test(hta$tad1~factor(hta$sexo)
    ,alternative='two.sided',exact=TRUE, correct=FALSE)

hta%>% 
  group_by(sexo) %>% 
  summarise(median = median(tad1)) 
```

 - Null Hypothesis cannot be rejected
 
 
 
   
# Paired T-test



```{r pairttest , mysize=TRUE, size='\\small'}
t.test(hta$tas1,hta$tas12,paired=TRUE)

summary(hta$tas1)
summary(hta$tas12)
```
 - P value is over 0.05
 
    
# Paired Sign-Rank Wilcoxon Test
 
```{r pwilcest , mysize=TRUE, size='\\small'}
wilcox.test(hta$tad1,hta$tad12, exact=TRUE, paired=TRUE)

```




# Read diabetes data

```{r , mysize=TRUE, size='\\tiny'}
require(pacman)
p_load(readxl, dplyr, magrittr)
diabetes <- read_excel("datasets/diabetes.xls")
sapply(diabetes, class)
diabetes_factor <- diabetes %>%
  mutate_if(sapply(diabetes, is.character), as.factor) %>%
  select (-numpacie)

diabetes%>% 
  group_by(ecg) %>% 
  summarise( n=n(),
    mean = mean(edat),
            sd=sd(edat)) 

```




# ANOVA

```{r}

anova<-aov(edat~ecg,data=diabetes_factor)
summary(anova)

```

# Multicomparison

```{r  , mysize=TRUE, size='\\tiny'}

library(multcomp)
tuk <- glht(anova, linfct = mcp(ecg = "Tukey"))

  print(summary(tuk)) # pairwise tests
  
```
---

```{r  , mysize=TRUE, size='\\tiny'}  
  print(confint(tuk, level=0.95)) # confidence intervals

```

# Multicomparison plot
```{r  , mysize=TRUE, size='\\small', eval=FALSE}

  plot(confint(tuk))
```

# Kruskal-Wallis Test

```{r , mysize=TRUE, size='\\small'}
diabetes_factor%>% 
  group_by(ecg) %>% 
  summarise(median = median(edat)) 

kruskal.test(edat~ecg,data=diabetes_factor)
```

# Dunn Test for multiple comparison

```{r , mysize=TRUE, size='\\small'}

library(dunn.test)
with(diabetes_factor,dunn.test(edat,ecg,method="bonferroni"))
```
 