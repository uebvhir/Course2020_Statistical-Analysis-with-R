---
title: "Statistics with R. Testing with continuous variables"
author: "UEB"
output:
  html_document:
    df_print: paged
  html_notebook:
    code_folding: show
editor_options: 
  chunk_output_type: console
---


```{r, echo = FALSE, results = 'hide', message = F}
require(knitr)
# include this code chunk as-is to set options
opts_chunk$set(fig.width = 7, fig.height = 3, warning = F, message = FALSE)


# knitr::knit_hooks$set(output = function(x, options) {
#   paste0('<small> \n ', x, '</small> \n ')
# })

```

# Outline

- Introduction

- Type of Tests

- Normality Tests

- One Group Comparison

- Two Groups Comparison 

- K Groups Comparison in Independent Samples

- Multiple Comparisons and Multiple Testing




# Introduction 

- Once the concept of hypothesis testing is established, 
- Researchers face the problem of _which test should be applied at every possible situation_.
- For this, ideally, they should... 
  - understand the problem and the questions addressed,
  - know available tests for each problem,
  - know (how to check) applicability assumptions of each test,
  - know how robust each test is to assumptions violation.
- Easier to say than to do. 
  - Sometimes cheatsheets may be helpful, but be warned against a blind use, that is understand and be critic with the steps. 

## Which test is appropriate for which problem

```{r, echo=FALSE, out.width="80%", out.length="60%", fig.cap=""}
knitr::include_graphics("images/testsXCadaSituacio.png")
```


## Example situation (1): Introduction

- Many experimental questions may be answered through hypothesis testing.
- Imagine, for example, a study designed to compare two distinct hypertension control programs.
- 60 individuals with HTA were randomly assigned to either one or the other group (30 per group) 
- Blood pressure was measured each month during a year 
  - For simplicity we may keep only data at months 1 and 12

```{r loadlibs, echo=FALSE, include=FALSE}
require(pacman)
p_load(dplyr, readxl, magrittr, ggplot2)
```


## Example situation (2): Data collected

```{r readExampleData , echo=TRUE}
hta <- read_excel("datasets/hta.xls")
htaSimple <- hta %>% select(grupo, sexo, tas1, tad1, tas12, tad12)
head(as.data.frame(htaSimple))
```

<!-- - Exercise: modify the code to create two new variables "difftas=tas12-tas1" and "difftad=tad12-tad1". -->



## Example situation (3): Reasonable questions

- The goal of the study is to compare the treatment effect
so a reasonable question is:
  - *Is the average decrease in "tad" the same in both groups A and B?*

- Or, if we are testing a new treatment "B", hat is intended to be batter than "A"
  - *Is the average decrease in "tad" greater in group B?*
  
- *Although they are not planned in this study* other relevant questions may lead to questions that need a test to be answered, such as:
  - *Is the average `tad` above 150?*
  - *Has the average `tad` (in group A) decreased in 12 months?*
  - *Is the average `tad` different in men and women at basal time?*
  


## Types of tests (1): Confirmatory vs Independence

Distinct classifications can be found in textbooks

- Confirmatory
  - Is average HTA above 150?
  - Is the the tas1 variable normally distributed
- Independence
  - Is sex related to HTA (or is mean(HTA) the same in men or women)
  - Is average HTA decrease the same for both groups?

- *This classification is useful but artificial, not to say that the term "independence" is slightly abused*



## Types of tests (2): Parametric vs Non-parametric

- Parametric tests 
  - assume some underlying distribution for the data
  - pose the test in terms of the distribution's parameters
    - E.g. the t-test assumes normality and relies on the normal and t-distribution's parameters
  
- Non-parametric tests
  - Do not assume an underlying distribution, but they are not assumption-free!
  - Check: [Distribution free is not assumption free](https://www.isixsigma.com/hypothesis-testing/nonparametric-distribution-free-not-assumption-free/)
  
- Permutation tests
  - If sample size is not tiny *permutation tests* are a good alternative.


## Hands on: Always start looking at the data

\scriptsize

```{r , eval=FALSE}
p_load(patchwork, ggplot2)

p1 <- ggplot(hta, aes(y = tas1)) +
  geom_boxplot() 

p2 <- ggplot(hta, aes(x = tas1)) +
  geom_histogram() 


p3 <- ggplot(hta, aes(y = tas12)) +
  geom_boxplot() 

p4 <- ggplot(hta, aes(x = tas12)) +
  geom_histogram() 

(p1 + p2) / (p3 )

```

\normalsize
## Hands on: Always start looking at the data

\scriptsize

```{r , eval=FALSE}
p_load(ggplot2, patchwork)

p1 <- ggplot(hta, aes(y = tas1)) +
  geom_boxplot(fill = "skyblue") +
  labs(title = "Box-plot", y = "tas1") 

p2 <- ggplot(hta, aes(x = tas1)) +
  geom_histogram(bins = 30, fill = "salmon", color = "black") +
  labs(title = "Histograma", x = "tas1")


(p1 | p2) 

```

\normalsize


## Data visualization

```{r , echo=FALSE, fig.height=5, fig.width=9}
p_load(ggplot2, patchwork)

p1 <- ggplot(hta, aes(y = tas1)) +
  geom_boxplot(fill = "skyblue") +
  labs(title = "Box-plot", y = "tas1") 

p2 <- ggplot(hta, aes(x = tas1)) +
  geom_histogram(bins = 30, fill = "salmon", color = "black") +
  labs(title = "Histograma", x = "tas1")


(p1 | p2) 
```



# Normality and tests

- The choice of test seems to pivot around the question of ¿is my data normally distributed?

- Leaving apart a tence to repeat what we have been taught, why is this so?

  - If the data is normally distributed there exist some *optimal tests* for some one or two sample problems.
  - Data show often a bell-shaped form that can be assimilated to have a gaussian distribution (it is *normal* to observe this).
  - Iven if data is not bell-shaped, if sample size is big enough th sample mean tends to be bell -shaped as sample size increase.
  
- In summary, normality is not only "practical" but common.

- As a consequence checking normality has become one of the first steps of any data analysis. 
  - It doesn't hurt, but it is clearly over-rated.



## Normality Test

- Normality tests can be used to decide if the data can be considered to follow a normal distribution.
- This is more a theoretical than practical issue because ...
  - If the sample size is too small, the test is not powerful enough.
  - If the sample size is too big, the test will almost always reject the normality htypothesis
  
- Normality can be tested 
  - Graphically:
    - Check if it is a symmetric distribution
    - Probability graphs (QQ-plots)
  - Using Hypothesis test (Normality)
    - Kolmogorov tests
    - Shapiro-Wilks test

## Normality test: Graphically

```{r}
 ggplot(hta, aes(sample = tas1)) +
  stat_qq() +
  stat_qq_line(color = "blue") +
  labs(title = "QQ plot", x = "Teórico", y = "Muestra") 
```


## Normality test: Shapiro-Wilks

- In normality test, the null hypothesis is normality
- That is, rejecting the null suggests departure of normality.
  - $H_0$: The data follow a normal distribution
  - $H_1$: The data do not follow a normal distribution
  
\scriptsize

```{r normtest }
shapiro.test(hta$tas12)  # Shapiro Wilk test

```



# One sample tests

- One sample tests refer to a single characteristic of the population such as:
  - *Is it true that the average tad in HTA population is above 150*?
  
- It is often said that they are less interesting because they are rarely used in most practical situations where the main goal is comparison

- *However*, noticing that a paired tests is equivalent to a one sample tests for the difference makes us realize their relevance.


## One sample parametric vs non-parametric tests

- If we assume normality an appropriate test for a hypothesis about the mean is the *t-test*

  - $H_0: \mu=\mu_0,\qquad H_1: \mu \neq \mu_0,\, (\mu > \mu_0,\, \mu< \mu_0)$.
  
- If we don't assume normality we can rely on
  - Wilcoxon rank test, if data re symmetrical
  - Sign test in other cases

## Hands on one sample tests (1): t-test

- Is `tad` in HTA patients above 90?
- Notice that even if we are interested in "above 90" the null is "equality"

  - $H_0: \mu=90,\qquad H_1: \mu > 90$.

\scriptsize

```{r onettest , size='\\tiny'}
t.test(hta$tad1, mu = 90) # One sample T.test
```

## Hands on one sample tests (2): Wilcoxon test

- In wilcoxon test the null hypothesis is about the median.
\scriptsize


```{r onewilcoxtest , size='\\tiny'}
wilcox.test(hta$tad1, mu = 90, alternative = "greater")  # One sample wilcoxon
```


# Two sample tests

\scriptsize


```{r}
head(hta)
```


## Homogeneity variance Test

\scriptsize


```{r vartest }
library(car)
hta %>% 
  group_by(sexo) %>% 
  summarise(var = sd(tas1)) 


leveneTest(hta$tad1 ~ factor(hta$sexo), center = "median") 

```
  - p value is over 0.05
  - We can assume homogeneity of variances
  
  
  
## T test when variances are equal


\scriptsize


```{r eqttest }
t.test(hta$tas1~factor(hta$sexo), var.equal = TRUE )

t.test(hta$tas1~factor(hta$sexo))

```
- Type I Error is over than 0.05
- We cannot reject mean equality



  
## T test when variances are unequal

\scriptsize



```{r neqttest }
t.test(hta$tas1~factor(hta$sexo),var.equal = FALSE )

```
- Same conclusions as before
- Test is also known as Welch test



  
## U Mann-Whitney or Sum Rank non parametric test

\scriptsize



```{r umtest }
wilcox.test(hta$tad1 ~ factor(hta$sexo), alternative = 'two.sided')

hta  %>%  group_by(sexo) %>% 
  summarise(median = median(tad1)) 
```

 - Null Hypothesis cannot be rejected
 
 
 
   
## Paired T-test

\scriptsize



```{r pairttest }
t.test(hta$tas1,  hta$tas12,  paired = TRUE)

t.test( hta$tas1 - hta$tas12)

summary(hta$tas1)
summary(hta$tas12)
```
 - P value is over 0.05
 
    
## Paired Sign-Rank Wilcoxon Test

 \scriptsize

```{r pwilcest }
wilcox.test(hta$tad1,hta$tad12, exact=TRUE, paired=TRUE)
wilcox.test(hta$tad1,hta$tad12, paired=TRUE)

```




## Read diabetes data

\scriptsize


```{r , size='\\tiny'}
require(pacman)

p_load(readxl, dplyr, magrittr)

diabetes <- read_excel("datasets/diabetes.xls")

sapply(diabetes, class)

diabetes <- diabetes %>%
  mutate_if(sapply(diabetes, is.character), as.factor) 

diabetes %>% 
  group_by(ecg) %>% 
  summarise( n = n(),
    mean = mean(edat),
            sd = sd(edat)) 

```




## ANOVA
\scriptsize


```{r}

anova <- aov(edat ~ ecg, data = diabetes_factor)
summary(anova)

ggplot(diabetes, aes(x = ecg , y = edat )) +
  geom_boxplot()


```

## Multicomparison
\scriptsize


```{r }
p_load(multcomp)

tuk <- glht(anova, linfct = mcp(ecg = "Tukey"))

summary(tuk) # pairwise tests
  
```


```{r }  
confint(tuk, level = 0.95) # confidence intervals

```

## Multicomparison plot

\scriptsize


```{r  , eval=TRUE}
plot(confint(tuk))
```

## Kruskal-Wallis Test
\scriptsize



```{r }
diabetes_factor %>%  
  group_by(ecg) %>% 
  summarise(median = median(edat)) 

kruskal.test(edat ~ ecg,data = diabetes_factor)
```

## Dunn Test for multiple comparison
\scriptsize



```{r }
p_load(dunn.test)

dunn.test(diabetes_factor$edat, diabetes_factor$ecg, method = "bonferroni")
```
 